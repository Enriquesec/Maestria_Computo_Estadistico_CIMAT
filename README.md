# Ciencia_de_datos

En este repositorio se encuentra todos los recursos (nota, tareas, proyectos, articulos, examenes) para la asignatura en Ciencia de Datos, impartida en Enero-Junio 2021 en la maestría de Computo Estadistico, CIMAT.

### Tareas
1. [Tarea 1. Visualizaciones](Tareas/Tarea_1)
2. [Tarea 2. Reducción de dimensionalidad](Tareas/Tarea_2)
	- PCA
	- Índice de marginación (CONAPO)
	- Eigenfaces
3. [Tarea 3. Métodos de Clustering clasicos](Tareas/Tarea_3)
	- Algoritmo EM para ajustar un modelo de mezclas de Gaussinas (MMG)
	- Kernel k-means
	- Clasificación de frutas
4. [Tarea 4. Reducción de dimensionalidad y clustering](Tareas/Tarea_4)
5. [Tarea 5. Métodos de Clustering: LDA, QDA y Regresión logística](Tareas/Tarea_5)
	 - Clasificación de dígitos a mano (MNIST)
	 - Análisis de textos y de sentimientos.
6. [Tarea 6. Métodos de Clustering: Redes neuronales, SVM, Arboles de clasificación y AdaBoost]

### Proyectos: 
- [Regularización en Métodos de regresión](Proyecto_final/)
En este trabajo desarrollamos la teoría de los principales métodos de regularización (*Ridge, LASSO y Elastic Net*), enfocándonos en regresión lineal múltiple para poder comprender estos conceptos en su forma más básica. Realizamos una análisis comparativo entre estos métodos, resaltando las ventajas y desventajas que tienen, además de los supuestos que se deben de cumplir para tener buen rendimiento. Posteriormente, realizamos una extensión del método de regularización aplicado en regresión multivariada múltiple presentando la teoría y un ejercicio práctico. Y por último, concluimos resaltando la importancia de estos métodos de regularización que tienen actualmente no solo en problemas de regresión. 

### Artículos: 
- Bradley Efron (2020) Prediction, Estimation, and Attribution, Journal of the American Statistical Association, 115:530, 636-655, DOI: 10.1080/01621459.2020.1762613
- Dhillon, I., Guan, Y., & Kulis, B. (2004). A Unified View of Kernel k-means , Spectral Clustering and Graph Cuts.
- Friedman, J. (1987). Exploratory Projection Pursuit. Journal of the American Statistical Association, 82(397), 249-266. doi:10.2307/2289161
- Gabriel, K. (1971). The Biplot Graphic Display of Matrices with Application to Principal Component Analysis. Biometrika, 58(3), 453-467. doi:10.2307/2334381
- Schölkopf, B., Herbrich, R., & Smola, A. (2001). A Generalized Representer Theorem. COLT/EuroCOLT.
- Gower, J. (1971). A General Coefficient of Similarity and Some of Its Properties. Biometrics, 27(4), 857-871. doi:10.2307/2528823
- van der Maaten, L. & Hinton, G. (2008). Visualizing Data using t-SNE . Journal of Machine Learning Research, 9, 2579--2605.
- Andrew Y. Ng, Michael I. Jordan, and Yair Weiss. 2001. On spectral clustering: analysis and an algorithm. In Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic (NIPS'01). MIT Press, Cambridge, MA, USA, 849–856.
-  Meilă, M. &amp; Shi, J.. (2001). A Random Walks View of Spectral Segmentation. <i>Proceedings of the Eighth International Workshop on Artificial Intelligence and Statistics</i>, in <i>Proceedings of Machine Learning Research</i> R3:203-208 Available from http://proceedings.mlr.press/r3/meila01a.html. Reissued by PMLR on 31 March 2021.
- Jianbo Shi and J. Malik, "Normalized cuts and image segmentation," in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no. 8, pp. 888-905, Aug. 2000, doi: 10.1109/34.868688.

### Bibliografía sugerida:
- T. Hastie, R. Tibshirani, J. Friedman. The elements of statistical learning. Data mining, inference and prediction. 2nd. edition. Springer, 2009.
- A. J. Izenman. Modern Multivariate Statistical Techniques. Regression, classification and manifold learning. Springer, 2013.
- R.O. Duda, P. Hart, D.G. Stork. Pattern classification. 2nd. edition. Wiley, 2000.